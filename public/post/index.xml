<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on An Rí Rua</title>
    <link>/post/</link>
    <description>Recent content in Posts on An Rí Rua</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <copyright>UA-135362222-1</copyright>
    <lastBuildDate>Wed, 17 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MDI: Weeks 8 &amp; 9</title>
      <link>/post/weeks-8-9/mdi-weeks-8-9/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/weeks-8-9/mdi-weeks-8-9/</guid>
      <description>Summary In this period I went to Women in Data Science (WiDS), Zurich, got the HPC scripts running properly (an &amp;amp; lost me a day or two), briefly inspected mixing for the gene sets Chris gave me and got the MATLAB version of MDI running (possibly incorrectly - I have to ask PK).
 WiDS Some nice speakers that were of particular interest to me:
Maria Rodriguez Martinez of IBM gave a talk on predicting drug effectiveness which was interesting and overlapped with the Dream challenge from last year; Natasha Antropova of Google DeepMind talked about their collaboration with CRUK on working at breast cancer diagnosis via computer vision; Sandhya Prabhakaran talked about Bayesian fuzzy clustering via an Indian Buffet process - an interesting talk but a little light on details (as to be expected at such an open conference perhaps); Ruth Urner talked about asymptotic bounds on ML methods and the ability to guarantee some bound on generalisability.</description>
    </item>
    
    <item>
      <title>MDI: Week 7</title>
      <link>/post/week-7/mdi-week-7/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/week-7/mdi-week-7/</guid>
      <description>Gene subsetting The aim of this week was to analyse the data at the level of the subsets provided by Chris. Basically we want to run the data through our pipeline in subsets of genes.
Pipeline The pipeline stands at:
Download the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data, remove NAs and apply vsn; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; and Apply MDI.</description>
    </item>
    
    <item>
      <title>MDI: Weeks 5 &amp; 6</title>
      <link>/post/weeks-5-6/mdi-weeks-5-6/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/weeks-5-6/mdi-weeks-5-6/</guid>
      <description>New work PCA plotting We implemented PCA across people (PCA across probes is too dense to be readable). We then eyeballed the results in each dataset and removed outlier individuals. This is not a rigourous method and we welcome arguments for a quantitative method to choose outliers.
First we load the relevant libraries (Dowle and Srinivasan 2019, Wickham et al. (2019), Kassambara and Mundt (2017), Bache and Wickham (2014))</description>
    </item>
    
    <item>
      <title>MDI: Week 4</title>
      <link>/post/mdi-week-4/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/mdi-week-4/</guid>
      <description>Sensible Clustering We check if the modal cluster from the MDI iterations is a sensible decision for allocating probes (note: we referred to median clustering previously. This was wrong). To do this we construct heatmaps comparing the clustering across a sample of iterations and also plot the adjusted Rand index for the clustering at every iteration compared to the modal clustering.
 We plot the adjusted Rand index comparing the allocation at a given iteration (corrected for thinning on the x-axis) to the modal clustering from all recorded iterations.</description>
    </item>
    
    <item>
      <title>MDI: Weeks 1 - 3</title>
      <link>/post/weeks-1-3/log-weeks-1-3/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/weeks-1-3/log-weeks-1-3/</guid>
      <description>Prelude Many of the R chunks below require these R packages (Kolde 2019, Dowle and Srinivasan (2019), Neuwirth (2014)):
library(pheatmap) library(data.table) library(RColorBrewer)  Reading The first step in the project is to understand the tool we are using. Therefore a study of Mason et al. (2016) and reading the manual of the associated program were the first steps. Expecting that this would have difficulties scaling to nine datasets different sampling methods were researched (Bardenet, Doucet, and Holmes 2017).</description>
    </item>
    
    <item>
      <title>An introduction to MDI</title>
      <link>/post/intro-mdi/an-introduction-to-mdi/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/intro-mdi/an-introduction-to-mdi/</guid>
      <description>Multiple Dataset Integration If we have observed paired datasets \(X_1=(x_{1,1},\ldots, x_{n,1})\), \(X_2=(x_{1,2},\ldots, x_{n,2})\), where observations in the \(i\)th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate.</description>
    </item>
    
  </channel>
</rss>