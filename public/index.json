[{"authors":["admin"],"categories":null,"content":"I am a MSc student currently writing my dissertation as part of the Wallace Group in the Department of Medicine at Cambridge University. The dissertation aims to define tissue specific gene sets by clustering gene expression data across multiple tissue types using Multiple Dataset Integration (MDI), an unsupervised clustering method based upon Dirichlet processes.\nPreviously I have worked with Paul Kirk, Laurent Gatto and Ollie Crook to extend MDI to a semi-supervised predictive tool in spatial proetomics. This is available online in tagm-mdi.\nI have also worked with Gerrit Gort, Elias Kaiser and Rachel Schipper to model the Farquhar-van Cammerer-Berry model of photosynthesis. As all of the data for this task is repeated measurements from individual plants, we hope to use mixed-effects models to account for this correlation in the data.\nMy research interests include Bayesian clustering applied to \u0026lsquo;omics data to extract biological information. Within \u0026lsquo;omics we have huge quantities of data; interpreting this and creating a coherent story of disease is a non-tirivial problem. My aim is to use Bayesian clustering methods (particularly non-parametric methods) in the area of immunology to help contribute to the understanding of disease.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a MSc student currently writing my dissertation as part of the Wallace Group in the Department of Medicine at Cambridge University. The dissertation aims to define tissue specific gene sets by clustering gene expression data across multiple tissue types using Multiple Dataset Integration (MDI), an unsupervised clustering method based upon Dirichlet processes.\nPreviously I have worked with Paul Kirk, Laurent Gatto and Ollie Crook to extend MDI to a semi-supervised predictive tool in spatial proetomics.","tags":null,"title":"Stephen D. Coleman","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536447600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536447600,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":[],"content":" This project is immensely enabled by the R programming language (R Core Team 2019). Most data analysis and processing was carried out within R using a number of packages. The packages from Wickham et al. (2019) (data processing and wrangling), Bache and Wickham (2014) (data processing), Wickham (2016) (visualisation), Müller and Wickham (2019) (data storage) and Dowle and Srinivasan (2019) (reading, writing and processing data) deserve special mention as they tend to be imported in multiple of my scripts for multiple purposes.\nI have fallen behind in tracking my progress, so starting afresh.\nMDI: Tissue specific gene sets Introduction We want to apply multiple dataset integration (MDI) (P. Kirk et al. 2012), a Bayesian unsupervised clustering method, to gene expression data from various tissue / cell types to create tissue specific gene sets. We are using the data from the Correlated Expression and Disease Association Research (CEDAR) cohort (The International IBD Genetics Consortium et al. 2018).\nWe have 9 .csv files, one for each tissue / cell type present of normalised gene expression data for 323 individuals. These are healthy individuals of European descent; the cohort consists of 182 women and 141 men with an average age of 56 years (but ranging from 19 to 86). None of the individuals are suffering from any autoimmune or inflammatory disease and were not taking corticosteroids or non-steroid anti-inflammatory drugs (with the exception of aspirin).\nWith regards to tissue types, samples from six circulating immune cells types:\nCD4+ T lymphocytes (CD4); CD8+ T lymphocytes (CD8); CD14+ monocytes (CD14); CD15+ granulocytes (CD15); CD19+ B lymphocytes (CD19); and platelets (PLA).  Data from intestinal biopsies are also present, with sample taken from three distinct locations:\nthe illeum (IL); the rectum (RE); and the colon (TR).  Not every individual is present in every dataset. However, as we are clustering genes this should not present a problem\nWhole genome expression data were generated using HT-12 Expression Beadchips following the instructions of the manufacturer (Illumina). 29,464 autosomal probes (corresponding to 19,731 genes) were included across the datasets, but further thinning under various criteria reduced this further in each dataset. The fluorescence intensities were \\(\\log_2\\) transformed and Robust Spline Normalized with Lumi38.\nIt should be noted that some datasets are less information rich than others (for instance the platelets dataset has only around 8 thousand probes present).\n Pipeline Overview of steps currently implemented:\nDownload the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data and remove NAs; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; Apply MDI (either as implemented by Mason et al. (2016) or the original MATLAB code); and Inspect the output under several areas: Convergence of the \\(\\phi\\) parameter between datasets over iterations; The disctribution of the \\(\\phi\\) parameter samples over MCMC iterations; The posterior similarity matrix (PSM) for the clustering over MCMC iterations; The adjusted rand index comparing the clustering in each iteration to the predicted clustering using Simtocl() from the mcclust (Fritsch 2012) package in R; Inspect the clustering with the expression data using the pheatmap function (Kolde 2019).    Transpose the data and remove NAs The data comes in the form [people \\(\\times\\) probes]. As we are interested in clustering genes (represented by the probes), we wish to transpose the data to fit the format required by MDI. Furthermore, MDI cannot handle NAs. We therefore wish to either remove NAs or impute a value in. As the missingness is not at random as if the expression levels are too low for a given reading it is left empty. This means we will fill NAs with the minimum expression value in the given row. However, if a probe is missing across a significant number of people (defined here as being above some fraction of the people present), we remove it from the dataset. We use an initial value of 0.1 for this threshold.\nFor the small and medium gene sets, no people or probes are removed under this criterion; for the big gene set we have the following loss:\n   Probes dropped People dropped    CD14 1 0  CD15 2 0  CD19 3 0  CD4 1 0  CD8 1 0  IL 2 0  PLA 1 0  RE 2 0  TR 1 0     PCA and visualisation We inspect the data to get some insight into underlying structure using PCA (as implemented in the factoExtra package by Kassambara and Mundt (2017)). This step can also be used to identify outliers that might be removed.\n Re-arrange the order We want the same rownames and the order of rownames (here probe IDs) in each dataset. Some probes are not present in every dataset and these are added with an expression level of 0 (well below the minimum value representing observed data). We then put each dataset in the same order of probes.\n MDI We have a choice of two flavours of MDI.\nThe C++ implementation from Mason et al. (2016); or The MATLAB implementation from P. Kirk et al. (2012) and used for glioblastoma subtyping by Savage et al. (2013).  The C++ version is faster and can handle the full 9 datasets. However, the MATLAB code includes a split-merge step (Dahl 2005) that is designed to help the program explore the full posterior space.\nC++ implementation and many seeds We have observed that the C++ version is given to becoming stuck in a single clustering and not exploring the space much at all.\nClustering across iterations for each probe in the TR dataset. Notice how quickly it becomes stuck.\n Ideally the MATLAB code should overcome this issue but we also consider model averaging. The idea is that we take \\(n\\) start points for the C++ code, thin aggressively (on the basis that as the code becomes stuck quickly, the clustering in the final iteration is representative of the entire run) and treat this recorded clustering as a single draw from the posterior space and use the \\(n\\) draws to decribe the clustering. To do this we use \\(n\\) different random seeds and run for a small number of iterations (initially 500) and keep only the 500th iteration in each run. We then use a python script to collapse these values into one .csv file of the same format as if we had run \\(n\\) iterations using the vanilla C++ implementation.\n MATLAB implementation The MATLAB code uses more memory and thus is limited to at most 7 datasets. We remove PLA and CD15; PLA has a lot less gene expression data present (as one would expect in platelets as they lack a nucleus, so any RNA present is residual from before differentiation occurred), from previous analysis (see post 1 for details) we have seen that the CD15 dataset is less similar to the others and is thus unlikely to contribute much to an integrative clustering method.\nHeatmap of clustering for all 9 datasets and all probes. Notice how PLA has more empty probes (cluster 0 here) and that both CD15 and PLA are further away from the other datasets in the hierarchical clustering.\n The MATLAB includes a split-merge step where at every \\(i^{th}\\) iteration of MCMC, random clusters are attempted to be merged or split. This is meant to help the algorithm explore the posterior space more throoughly.\n  Analysis We inspect the PSMs as representative of the clustering including uncertainty. We inspect the \\(\\phi_{ij}\\) parameters from MDI; these are associated with two given datasets, dataset \\(i\\) and dataset \\(j\\) here, and are indivative of global similarity between them. \\(\\phi_{ij}\\) is a random variable sampled from a Gamma distribution where the shape parameter is defined by the number of observations (in our case probes) with the same label in the two datsets - thus the greater the \\(\\phi_{ij}\\) the more correlated the clustering between the datasets is.\n\\(\\phi\\) plotted over iterations We inspect a scatter plot of the values sampled for \\(\\phi\\) over iterations.\n\\(\\phi_{1,3}\\) (between CD14 and CD4) after 500 iterations for 5,000 different initailsiations.\n \\(\\phi_{1,3}\\) (between CD14 and CD4) after 1,225 iterations for the MATLAB implementation.\n  Distribution of \\(\\phi\\) over iterations We inspect histograms of the sampled values for \\(\\phi\\).\nHistogram of values of \\(\\phi_{1,3}\\) (between CD14 and CD4) sampled in 500th iteration for 5,000 different initialisations.\n Histogram of values of \\(\\phi{1,3}\\) (between CD14 and CD4) sampled over 1,225 iterations with a thinning factor of 25 for the MATLAB implementation.\n  Adjusted rand index plots Compare clustering in final iteration to all previous clusterings using the adjusted rand index.\n   PSMs PSMs\n   Gene expression data We include heatmaps of the gene expression data annotated by the clustering predicted by the PSMs. For the “Many seeds”\u0026quot; approach there are too many clusters generated by Simtocl() to annotate - this is due to the uncertainty of the clustering.\n   Fused genes For the many seeds implementation we have no fused genes between any datasets.\n    Compare clustering in MATLAB to MDI We compare the predicted clustering in the MATLAB implemenation to the clustering at each iteration of the Many seeds approach.\nHistograms of the distribution of the adjusted rand index between the clustering at each seed for C++ MDI compared to the predicted clustering of the MATLAB MDI, facetted by dataset.\n We compare the PSM for MATLAB and C++ (in the same ordering) and for the gene expression data. It appears that the clustering present in the C++ with many seeds is an uncertain version of the MATLAB. The MATLAB becomes stuck and has each member of each cluster allocated to the same cluster with each iteration (giving this binary similarity matrix). The many seeds PSM has many of the blocks / clusters visible in the MATLAB PSM, but their membership is less well defined - this method captures the uncertainty around the membership. This is reassuring - we can see that this model averaging does relate to the MATLAB while avoiding the problem of the spikey likelihood surface. However, this less distinct membership is harder to translate into clusters.\nA small sense check is that the empty probes are all confidently assigned to the same cluster regardless of initialisation and method (the well defined block in the centre of the two PSMs).\nWe see that the gene expression for the CD14 data within the small gene set aligns nicely with the clusters. We see that there is more of a continuum between clusters for the many seeds approach - we notice that the top row of gene cluster most strongly with each other, but then with their neighbours in the expression space. Sometimes some of these genes cluster with the genes at the very bottom of the gene expression heatmap or with the band directly above the band of genes with an expression level of 0 across all people. This is satisfying - there is a relatively strong cluster (that one may pick out by eye in the expression data), but that the boundary between this and it’s neighbours is not overly distinct.\n  Bibliography Bache, Stefan Milton, and Hadley Wickham. 2014. Magrittr: A Forward-Pipe Operator for R. https://CRAN.R-project.org/package=magrittr.\n Dahl, David B. 2005. “Sequentially-Allocated Merge-Split Sampler for Conjugate and Nonconjugate Dirichlet Process Mixture Models,” 27.\n Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n Fritsch, Arno. 2012. Mcclust: Process an Mcmc Sample of Clusterings. https://CRAN.R-project.org/package=mcclust.\n Kassambara, Alboukadel, and Fabian Mundt. 2017. Factoextra: Extract and Visualize the Results of Multivariate Data Analyses. http://www.sthda.com/english/rpkgs/factoextra.\n Kirk, Paul, Jim E. Griffin, Richard S. Savage, Zoubin Ghahramani, and David L. Wild. 2012. “Bayesian Correlated Clustering to Integrate Multiple Datasets.” Bioinformatics 28 (24): 3290–7. doi:10.1093/bioinformatics/bts595.\n Kolde, Raivo. 2019. Pheatmap: Pretty Heatmaps. https://CRAN.R-project.org/package=pheatmap.\n Mason, Samuel A, Faiz Sayyid, Paul DW Kirk, Colin Starr, and David L Wild. 2016. “MDI-Gpu: Accelerating Integrative Modelling for Genomic-Scale Data Using Gp-Gpu Computing.” Statistical Applications in Genetics and Molecular Biology 15 (1). De Gruyter: 83–86.\n Müller, Kirill, and Hadley Wickham. 2019. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.\n R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n Savage, Richard S., Zoubin Ghahramani, Jim E. Griffin, Paul Kirk, and David L. Wild. 2013. “Identifying Cancer Subtypes in Glioblastoma by Combining Genomic, Transcriptomic and Epigenomic Data.” arXiv:1304.3577 [Q-Bio, Stat], April. http://arxiv.org/abs/1304.3577.\n The International IBD Genetics Consortium, Yukihide Momozawa, Julia Dmitrieva, Emilie Théâtre, Valérie Deffontaine, Souad Rahmouni, Benoît Charloteaux, et al. 2018. “IBD Risk Loci Are Enriched in Multigenic Regulatory Modules Encompassing Putative Causative Genes.” Nature Communications 9 (1): 2427. doi:10.1038/s41467-018-04365-8.\n Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n    ","date":1558483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558483200,"objectID":"b1dd75e1414ce37a601ada5d089c313f","permalink":"/post/weeks-15-16/mdi-week-15-16/","publishdate":"2019-05-22T00:00:00Z","relpermalink":"/post/weeks-15-16/mdi-week-15-16/","section":"post","summary":"This project is immensely enabled by the R programming language (R Core Team 2019). Most data analysis and processing was carried out within R using a number of packages. The packages from Wickham et al. (2019) (data processing and wrangling), Bache and Wickham (2014) (data processing), Wickham (2016) (visualisation), Müller and Wickham (2019) (data storage) and Dowle and Srinivasan (2019) (reading, writing and processing data) deserve special mention as they tend to be imported in multiple of my scripts for multiple purposes.","tags":[],"title":"MDI: Week 15 \u0026 16","type":"post"},{"authors":null,"categories":[],"content":" Summary This period has been a bit strange - the Easter bank holiday, MASAMB and a wedding in Ireland saw a number of days lost for MDI work (approximately 10). What have we done in this period:\nRun MATLAB MDI on the small gene sets (n = 102 probes) across 7 key datasets (we dropped CD15 and PLA); Ran Many seeds MDI (this is Mason’s implementation using multiple start points) on the same data; and Inspected and compared outputs.  Running MATLAB Our first impression is MATLAB is odd. If one calls a function in a script, the call must be before the function definition. This seems completely non-intuitive but otherwise it’s a grand language - easy to read and interpret despite no background.\nThe MATLAB implementation has the advantage of using the split-merge step outlined in (Dahl, n.d.) as part of the MCMC process. This attempts to split / merge clusters to overcome the problem of a “sticky” likelihood surface.\nThe MATLAB MDI has to do some intense book-keeping, tracking all the required interactions. This involves building a large vector of length \\(2^{(k \\times k-1)}\\) where \\(k\\) is the number of datasets. This consumes a huge amount of memory and limits us to 7 datasets for now.\nThe initial run had very few accepted split-merge steps and some oddities about the output. Increasing the amount of split-merge steps attempted at each step was an attempt at a solution to the first problem. The second problem only emerged in inspecting the output - it appeared that the clustering was still “sticky” (by which we mean the clustering stopped changing at an early iteration and remained fixed). Furthermore, the “empty” cluster (i.e. the cluster containing the probes that had an expression level of 0 as MDI requires the same members present in all datasets and cannot handle NAs) was very close to some non-zero probes - it was their nearest cluster unless we allowed many probes to inhabit their own cluster. My suspicion is that this was caused by the normalisation step in the MATLAB version of MDI, so we turned off this step in the belief it was not necessary as all the expression vlaues had already undergone \\(log_2\\) transformation and Robust Spline Normalisation and thus were on similar scales. Interestingly turning off normalisation slowed down the algorithm.\nHowever, this interpretation was wrong - the problem had been in the chocie of method to define clusters. Use of the Simtocl() function from the mcclust package in R (Fritsch 2012) overcame this issue. This is a function which interprets a posterior similarity matrix (PSM) as a clustering. In this case the normalised and unnormalised data do cluster slightly differently. Due to this we continue with unnormalised data from now on.\nThe updated MATLAB run was still quite sticky as can be seen in the PSM associated with each dataset - there is no points that move cluster after the hundreth iteration (we use a burn-in of 100 in the following heatmaps).\nPSM for TR dataset - MATLAB MDI with 1,163 iterations and no normalisation.\n PSM for TR dataset - MATLAB MDI with 1,163 iterations and normalisation.\n  Running Many seeds PSM for TR dataset - Many seeds MDI with 5,000 different random seeds.\n  Bibliography Dahl, David B. n.d. “Sequentially-Allocated Merge-Split Sampler for Conjugate and Nonconjugate Dirichlet Process Mixture Models,” 27.\n Fritsch, Arno. 2012. Mcclust: Process an Mcmc Sample of Clusterings. https://CRAN.R-project.org/package=mcclust.\n    ","date":1557878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557878400,"objectID":"0e1b353b6f95b45e0b23e7613b0ea5a1","permalink":"/post/weeks-10-14/mdi-weeks-10-14/","publishdate":"2019-05-15T00:00:00Z","relpermalink":"/post/weeks-10-14/mdi-weeks-10-14/","section":"post","summary":"Summary This period has been a bit strange - the Easter bank holiday, MASAMB and a wedding in Ireland saw a number of days lost for MDI work (approximately 10). What have we done in this period:\nRun MATLAB MDI on the small gene sets (n = 102 probes) across 7 key datasets (we dropped CD15 and PLA); Ran Many seeds MDI (this is Mason’s implementation using multiple start points) on the same data; and Inspected and compared outputs.","tags":["MDI","Chris Wallace","Paul Kirk"],"title":"MDI Weeks 10 - 14","type":"post"},{"authors":null,"categories":[],"content":" Summary In this period I went to Women in Data Science (WiDS), Zurich, got the HPC scripts running properly (an \u0026amp; lost me a day or two), briefly inspected mixing for the gene sets Chris gave me and got the MATLAB version of MDI running (possibly incorrectly - I have to ask PK).\n WiDS Some nice speakers that were of particular interest to me:\nMaria Rodriguez Martinez of IBM gave a talk on predicting drug effectiveness which was interesting and overlapped with the Dream challenge from last year; Natasha Antropova of Google DeepMind talked about their collaboration with CRUK on working at breast cancer diagnosis via computer vision; Sandhya Prabhakaran talked about Bayesian fuzzy clustering via an Indian Buffet process - an interesting talk but a little light on details (as to be expected at such an open conference perhaps); Ruth Urner talked about asymptotic bounds in the context of ML methods and their ability to generalise. Quite information theoretic, but very interesting.  Beyond this I had some nice conversations with:\nMargaux Penwarden of McKinsey/QuantumBlack about fairness and explainability in A.I.; Nicholas Kelley of Novartis about their plans for integrating machine learning into their business; and Lise Regnier from Warner Bros. She had given a great talk on being a data scientist in an environment unused to it and recommended the use osf SHapley Additive exPlanations (SHAP) a unified approach to explain the output of any machine learning model. I haven’t looked into this yet, but she claimed to use it to make more causal claims.  It was an interesting conference - got quite a bit of exposure to different ideas, problems and methods than I normally think about. Sarah Ebling’s talk on building tools to translate sign language and Michelle Sebag talking about meta-features are good examples of this. Beyond purely intellectual pursuits, I would reccommend this conference if one was coming towards a point where one was considering moving to industry or wanted to see what skills are sought in industry. There was quite a bit of fishing for candidates from different companies.\n HPC I had a bash script calling MDI across 1,000 seeds. As I am only recoring the 500th iteration I was running a number of these side-by-side in the node. I followed a post on Stack Exchange that reccommended using “\u0026amp;” to force things into parallel. However, slurm saw everything go into the background and assumed the script ran and killed it instantly. I had to include a “wait” command after my for loop to ensure that the script was not instantly terminated.\nStuart also helped out with installing R packages on the HPC - I’ve added his instrucitons to the group info doc a section since added to by Kath.\n Mixing in gene subsets The clusters do not become fixed as quickly in the small and medium-sized gene sets. Label flipping does seem to occur a little bit, but the mixtures are still a little sticky - comparing different seeds we see different numbers of clusters emerge in the datasets; we might have to use the Split-Merge step of the MATLAB code for the subsetted data too and we should consider model averaging if we don’t use this. In the big gene set the behaviour is quite similar to the full dataset.\nCD14 Rand index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n   IL Rand index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n   PLA Rand Index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n    ","date":1555459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"9ac173c4ada34684bdea36de222293af","permalink":"/post/weeks-8-9/mdi-weeks-8-9/","publishdate":"2019-04-17T00:00:00Z","relpermalink":"/post/weeks-8-9/mdi-weeks-8-9/","section":"post","summary":"Summary In this period I went to Women in Data Science (WiDS), Zurich, got the HPC scripts running properly (an \u0026amp; lost me a day or two), briefly inspected mixing for the gene sets Chris gave me and got the MATLAB version of MDI running (possibly incorrectly - I have to ask PK).\n WiDS Some nice speakers that were of particular interest to me:\nMaria Rodriguez Martinez of IBM gave a talk on predicting drug effectiveness which was interesting and overlapped with the Dream challenge from last year; Natasha Antropova of Google DeepMind talked about their collaboration with CRUK on working at breast cancer diagnosis via computer vision; Sandhya Prabhakaran talked about Bayesian fuzzy clustering via an Indian Buffet process - an interesting talk but a little light on details (as to be expected at such an open conference perhaps); Ruth Urner talked about asymptotic bounds in the context of ML methods and their ability to generalise.","tags":["MDI"],"title":"MDI: Weeks 8 \u0026 9","type":"post"},{"authors":null,"categories":[],"content":" Gene subsetting The aim of this week was to analyse the data at the level of the subsets provided by Chris. Basically we want to run the data through our pipeline in subsets of genes.\nPipeline The pipeline stands at:\nDownload the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data, remove NAs and apply vsn; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; and Apply MDI.  I made a mistake in originally doing step 1 after step 3, but this does not make sense as it is possible that the missingness is outside of this subset (so we do not have to remove any points) or entirely in this subset (in which case imputation may be misleading).\n Subsetting the data The gene subset data was saved in a list of Data frame’s. Not data.frame’s. Apparently Bioconductor has its own version of the data frame. Once we realised this and loaded the correct package this was not a problem.\nUsing the key relating probe IDs to genes and the names of the genes in the subsets we created smaller .csv files containing the expression data relating only to the probes present that map to these genes.\n Transpose, remove NAs and apply VSN The only point of note is that we had harsher cirteria for removing people / probes in the small and medium datasets. If there was 5% of points missing we stripped out the person / probe. This had no impact as none of the people or probes in these subsets are above this threshold of missingness.\nlibrary(data.table) small_obs_lost \u0026lt;- fread(\u0026quot;Observations_lost_small.csv\u0026quot;, header = T) med_obs_lost \u0026lt;- fread(\u0026quot;Observations_lost_med.csv\u0026quot;, header = T) head(small_obs_lost) ## File N_probes_lost N_people_lost ## 1: CD14_GE_Corrected4_Covars_smallnet 0 0 ## 2: CD15_GE_Corrected4_Covars_smallnet 0 0 ## 3: CD19_GE_Corrected4_Covars_smallnet 0 0 ## 4: CD4_GE_Corrected4_Covars_smallnet 0 0 ## 5: CD8_GE_Corrected4_Covars_smallnet 0 0 ## 6: IL_GE_Corrected4_Covars_smallnet 0 0 head(med_obs_lost) ## File N_probes_lost N_people_lost ## 1: CD14_GE_Corrected4_Covars_midnet 0 0 ## 2: CD15_GE_Corrected4_Covars_midnet 0 0 ## 3: CD19_GE_Corrected4_Covars_midnet 0 0 ## 4: CD4_GE_Corrected4_Covars_midnet 0 0 ## 5: CD8_GE_Corrected4_Covars_midnet 0 0 ## 6: IL_GE_Corrected4_Covars_midnet 0 0  PCA Individuals We identify outliers on a visual basis in the biplots. I will show a subset of plots as between the 3 subsets and 9 tissue types we have 27 plots which seems a little heavy. The script, with the full list of outliers dropped, is found here. I found tibbles a nice way of keeping track of gene subset, tissue and data. The final tibble held a column for each of these as well as a “Cleaned data” column. It made it very easy to have all the data in one place and to save it in a nice compressed form.\nPCA plot for individuals in the large subset of genes in the CD15 dataset.\n PCA plot for individuals in the medium subset of genes in the CD15 dataset.\n PCA plot for individuals in the small subset of genes in the CD15 dataset. Note that the outliers are the same individuals as the preceding plots.\n  Probes As we had smaller gene sets, the PCA for the Probes was also created. A sample of biplots is included.\nFor the small subset of genes:\nPCA for probe expression in small gene subset of CD4 dataset.\n PCA for probe expression in small gene subset of PLA dataset.\n For the medium subset of genes:\nPCA for probe expression in medium gene subset of CD8 dataset.\n PCA for probe epxression in medium gene subset of PLA dataset.\n    ","date":1553731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553731200,"objectID":"57de724bdfdc70648893389a05e405cb","permalink":"/post/week-7/mdi-week-7/","publishdate":"2019-03-28T00:00:00Z","relpermalink":"/post/week-7/mdi-week-7/","section":"post","summary":"Gene subsetting The aim of this week was to analyse the data at the level of the subsets provided by Chris. Basically we want to run the data through our pipeline in subsets of genes.\nPipeline The pipeline stands at:\nDownload the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data, remove NAs and apply vsn; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; and Apply MDI.","tags":["MDI"],"title":"MDI: Week 7","type":"post"},{"authors":null,"categories":[],"content":" New work PCA plotting We implemented PCA across people (PCA across probes is too dense to be readable). We then eyeballed the results in each dataset and removed outlier individuals. This is not a rigourous method and we welcome arguments for a quantitative method to choose outliers.\nFirst we load the relevant libraries (Dowle and Srinivasan 2019, Wickham et al. (2019), Kassambara and Mundt (2017), Bache and Wickham (2014))\n# Load data.table to access fread and fwrite functions library(data.table) # Load magrittr for the pipe %\u0026gt;% library(magrittr) # For select, filter library(dplyr) # For PCA plots library(factoextra, quietly = T)  Read in the data and create some variables to hold results. This data has had NAs filled using the minimum value present for that probe and removing the probe from that dataset if the probe has missing values for more than 0.1 of the people.\n# Read in data data_dir \u0026lt;- \u0026quot;/home/MINTS/sdc56/Desktop/blogdown_github_pages/content/post/weeks-5-6/Data\u0026quot; files_present \u0026lt;- list.files(path = data_dir) file_name \u0026lt;- grep(\u0026quot;Covars.csv\u0026quot;, files_present, value = TRUE) genes_present \u0026lt;- c() pca_lst \u0026lt;- list() pca_plot_lst \u0026lt;- list() data_lst \u0026lt;- list() # Put all the data in a list of data tables for (f in file_name) { data_lst[[f]] \u0026lt;- fread(paste(data_dir, f, sep = \u0026quot;/\u0026quot;), header = T) } # Acquire the relevant file names files_to_write \u0026lt;- strsplit(names(data_lst), \u0026quot;_?_(.*?)_?\u0026quot;) %\u0026gt;% lapply(\u0026quot;[[\u0026quot;, 2) %\u0026gt;% unlist() num_datasets \u0026lt;- length(data_lst) cleaned_data \u0026lt;- vector(\u0026quot;list\u0026quot;, 9) names(cleaned_data) \u0026lt;- files_to_write Apply the PCA.\nfor (i in 1:num_datasets) { # Carry out PCA and record the biplot raw_file_name \u0026lt;- file_name[[i]] edit_file_name \u0026lt;- files_to_write[[i]] pca_lst[[edit_file_name]] \u0026lt;- .res_pca \u0026lt;- prcomp(t(data_lst[[raw_file_name]][, -1])) pca_title \u0026lt;- paste0(edit_file_name, \u0026quot;: PCA for individuals\u0026quot;) pca_plot_lst[[edit_file_name]] \u0026lt;- fviz_pca_ind(.res_pca, col.ind = \u0026quot;contrib\u0026quot;, # gradient.cols = c(\u0026quot;#00AFBB\u0026quot;, \u0026quot;#E7B800\u0026quot;, \u0026quot;#FC4E07\u0026quot;), title = pca_title ) + scale_color_gradient2( low = \u0026quot;black\u0026quot;, mid = \u0026quot;blue\u0026quot;, high = \u0026quot;red\u0026quot;, midpoint = 1.0 ) } We then visually inspect the PCA plots and remove indviduals we deem to be outliers.\nBased on an inspection of this plot, we decide to remove IPC154 and IPC155 from the CD14 dataset for all following steps.\nSimilarly, for CD15 we remove IPC137. We continue in this vein for all of the 9 datasets.\n Variance stabilisation We wish to standardise the expresison values across probes and to do so apply variance stabilisation (Huber, Von Heydebreck, et al. 2002) after first converting the expression values from \\(log_2\\) scale. We do this in this script which can be called from the command line.\n Gene subsets We select three different subsets of genes using this RScript.\n  Pipeline summary Now our current workflow / pipeline can be described as:\nDownload the data from associated website; Transpose this data and remove and / or fill NAs using this script\n Remove NAs absent from 0.1 of the total people in the dataset; Otherwsie fill the missing values with the minimum present expression value for the probe in question.  (Optional) Select gene subsets; Remove outlier individuals using PCA as described above; Apply VSN using the R package (Huber, von Heydebreck, et al. 2002); and Run MDI.\n   References Bache, Stefan Milton, and Hadley Wickham. 2014. Magrittr: A Forward-Pipe Operator for R. https://CRAN.R-project.org/package=magrittr.\n Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n Huber, Wolfgang, Anja von Heydebreck, Holger Sueltmann, Annemarie Poustka, and Martin Vingron. 2002. “Variance Stabilization Applied to Microarray Data Calibration and to the Quantification of Differential Expression.” Bioinformatics 18 Suppl. 1: S96–S104.\n Huber, Wolfgang, Anja Von Heydebreck, Holger Sültmann, Annemarie Poustka, and Martin Vingron. 2002. “Variance Stabilization Applied to Microarray Data Calibration and to the Quantification of Differential Expression.” Bioinformatics 18 (suppl_1). Oxford University Press: S96–S104.\n Kassambara, Alboukadel, and Fabian Mundt. 2017. Factoextra: Extract and Visualize the Results of Multivariate Data Analyses. http://www.sthda.com/english/rpkgs/factoextra.\n Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n   ","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553212800,"objectID":"fce323d344389f211985cf5270011c3f","permalink":"/post/weeks-5-6/mdi-weeks-5-6/","publishdate":"2019-03-22T00:00:00Z","relpermalink":"/post/weeks-5-6/mdi-weeks-5-6/","section":"post","summary":"New work PCA plotting We implemented PCA across people (PCA across probes is too dense to be readable). We then eyeballed the results in each dataset and removed outlier individuals. This is not a rigourous method and we welcome arguments for a quantitative method to choose outliers.\nFirst we load the relevant libraries (Dowle and Srinivasan 2019, Wickham et al. (2019), Kassambara and Mundt (2017), Bache and Wickham (2014))","tags":["MDI"],"title":"MDI: Weeks 5 \u0026 6","type":"post"},{"authors":null,"categories":[],"content":" Sensible Clustering We check if the modal cluster from the MDI iterations is a sensible decision for allocating probes (note: we referred to median clustering previously. This was wrong). To do this we construct heatmaps comparing the clustering across a sample of iterations and also plot the adjusted Rand index for the clustering at every iteration compared to the modal clustering.\n We plot the adjusted Rand index comparing the allocation at a given iteration (corrected for thinning on the x-axis) to the modal clustering from all recorded iterations.\n We construct a heatmap of the clustering across a sample of iterations.\nIndividual clusterings We also cluster the individual datasets using a Dirichlet process (i.e. we apply MDI with a single dataset). We carry out similar sense checks to ensure that the model clustering is representative.\n  We compare the clustering in the individual vs the multiple dataset cases. Note that the specific label does not matter, we are interested in the membership of clusters but do not have any reason to expect that the labels should correspond. We see that many of the clusters have a largely common membership across the two clusterings, but that there are significant differences.\n    ","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"bad082c4af1759b37befde6516d089af","permalink":"/post/week-4/mdi-week-4/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/week-4/mdi-week-4/","section":"post","summary":"Sensible Clustering We check if the modal cluster from the MDI iterations is a sensible decision for allocating probes (note: we referred to median clustering previously. This was wrong). To do this we construct heatmaps comparing the clustering across a sample of iterations and also plot the adjusted Rand index for the clustering at every iteration compared to the modal clustering.\n We plot the adjusted Rand index comparing the allocation at a given iteration (corrected for thinning on the x-axis) to the modal clustering from all recorded iterations.","tags":["MDI","Chris Wallace","Paul Kirk"],"title":"MDI: Week 4","type":"post"},{"authors":null,"categories":[],"content":" Prelude Many of the R chunks below require these R packages (Kolde 2019, Dowle and Srinivasan (2019), Neuwirth (2014)):\nlibrary(pheatmap) library(data.table) library(RColorBrewer)  Reading The first step in the project is to understand the tool we are using. Therefore a study of Mason et al. (2016) and reading the manual of the associated program were the first steps. Expecting that this would have difficulties scaling to nine datasets different sampling methods were researched (Bardenet, Doucet, and Holmes 2017). Hamiltonian Monte Carlo appears a likely candidate to improve the rate of convergence, with Betancourt (2017) providing an explanation of the theoretical framework. These topics were of interest as the MDI implementation uses a Gibbs sampler. We expected that we could make gains in the computational tractability of using all 9 datasets in a single call of MDI with a more clever sampling method.\n Data handling MDI uses data that has common row names across all datasets. The data from the CEDAR cohort is in the form of [people \\(\\times\\) probes]. We want to transpose this; to accomplish this task we wrote an Rscript that can be called form the terminal command line with appropriate arguments to transpose .csv files in a given directory. The data.table package by Dowle and Srinivasan (2019) was of great use in making this quick to run - for our 9 datasets of ~300 people and 8-16 thousand probes it aaproximately 30s using a desktop compuer to read in, transpose, handle missingness and write the file. In comparison, using purrr of the tidyverse suite for even one aspect of the missingness handling increased the time taken to roughly 1 minute 50s.\nThe nine datasets present are six circulating immune cell types (CD4+ T lymphocytes, CD8+ T lymphocytes, CD19+ B lymphocytes, CD14+ monocytes, CD15+ granulocytes, platelets) as well as ileal, colonic, and rectal biopsies (IL, TR, RE datasets respectively).\nAnother script was required to remove all the non-ubiquitous probe IDs. Any probe not present in all datasets was removed to allow MDI to perform as MDI cannot handle missing data. This reduced the set of probes to 4,964.\nWe performed MDI on these 9 reduced datasets with 10,000 iterations, a burn-in of 1,000 and a thinning rate of 25. MDI overfits the data, beginning with 50 clusters (as an approximation of a Dirichlet process - note that we can change the number of clusters present); as part of the sampling is reduced to around 10 occupied clusters per dataset (ranging from 8 - 13). We assumed that the median cluster allocation was the predicted cluster forgetting about the label-flipping problem of unsupervised methods.\nWe constructed a dataframe of the median allocation per dataset for each probe. The probes are translated to the associated gene using the key available online. As some of the probes mapped to non-unique genes we use a matrix to hold our data (as this does not require unique row names in R). We read this in and visually inspect the head of the data.\n# Read in the data and convert to a matrix with apporpriate row names compare_df \u0026lt;- data.table::fread(\u0026quot;allocation_data_run_1.csv\u0026quot;) compare_df_mat \u0026lt;- as.matrix(compare_df[, -10]) row.names(compare_df_mat) \u0026lt;- compare_df$V1 # Inspect the data head(compare_df_mat) ## CD14 CD15 IL CD4 CD8 CD19 PLA RE TR ## GGACT 8 8 8 8 8 8 8 8 8 ## A4GNT 5 6 10 6 6 10 5 5 5 ## AAAS 3 8 3 3 3 3 5 3 3 ## AACS 8 10 8 8 8 8 8 8 8 ## AACSP1 8 6 6 6 8 8 5 6 6 ## NCEH1 10 8 10 10 10 10 8 11 10  Visualisation Note: As one inspects the following plots please recall that the labels are arbitrary and proximity of colouring has no significance (i.e. there is no reason to believe that orange in the heatplots has any association with red).\nUsing this data we generated a heatmap of all the genes allocation across all datasets.\nNotice that we have clusters of datasets; CD4, CD8 and CD14, RE and IL and then CD15, CD19 and TR. Platelets are outside of any clusters of datasets; PLA is also the thinnest dataset with only 8 thousand probes present in the full format.\nThere are 13 clusters present here; to enable comparison we went for a wider colour palette. This is the reason for the garishness of this heatplot. A casual inspection suggests lower similarity than one might expect, particularly considering the selection of data. As we only include the genes that are sufficiently expressed in each cell type to register for measurement we would expect these to include the genes that are most similarly expressed across all tissues. We should consider the pssibility that this is an artifact of not considering label-flipping, but we investigate the clusters in finer detail first.\nInvestigate different combinations We consider the data excluding the platelets. Even this change gives an appearance of greater similarity.\nRecalling the first heatmap of the entire dataset, which included clustering of columns (i.e. the datasets), we consider only the separate clustering of datasets: CD4, CD8, CD14, RE and IL.\nThese are more coherent than our first heatmap where we considered all datasets at once - this suggests that trying to process the output of all 9 datasets at once is a non-trivial task and the naive method of heatmapping all of the data is unlikey to be useful. However, by including clustering of the datasets it is a useful initial step in the exploratory data analysis and will be considered as part of our analysis workflow.\nOut of curiousity we check the clustering and heatmap for the excluded datasets.\nUnsurprisingly this is very noisy, with only small bands of genes clustering across multiple tissues.\n  Including all probes Next we attempt to include all probes present across the 9 datasets. The challenge here is to impute the missing probes in such a fashion as to not add noise to the final clustering. To do this we first inspect the spread of the expression values in the datasets. As this is too large to consider in normal summary statistics, we inspect histograms of these - we notice that all of the probe expression values have very similar means and standard deviations - these are densely (i.e. within 1.0 for the mean, within 0.2 for the standard deviation) distributed around 7.0 and 2.10 respectively.\nWe created an Rscript that finds the list of all unique probe IDs present across the 9 datasets and adds the required rows to each .csv file (filled with 0’s but any arbitrarily distant number from the range inhabitated by the actual measurements should be acceptable) and rearranging to have common row names and row orders in each dataset for all 18,517 prob IDs. Using these new datasets we perform MDI with the same arguments.\nThis script also saves a binary matrix indicating for each probe which datasets it is present in. We use this as part of a sense check to ensure that the cluster containing the imputed probes contains no other members. This is done by taking the Hadamard product of the binary matrix with the allocation matrix and comparing the clusters occupied in this to those of the allocation matrix. Ideally one of the clusters should have completed disappeared and been replaced by a 0 cluster. This is the case below.\nAs in the initial attempt we feed in our data and move the to a matrix format.\n# Read in the data and convert to a matrix with apporpriate row names compare_df_all \u0026lt;- data.table::fread(\u0026quot;allocation_data_run_2.csv\u0026quot;) compare_df_all_mat \u0026lt;- as.matrix(compare_df_all[, -10]) row.names(compare_df_all_mat) \u0026lt;- compare_df_all$V1 We now create a heatmap of these genes.\nNotice the clustering of datasets; we have groupings of the intestinal sample cells (IL, RE and TR), of CD14, CD19, CD4 and CD8 and then CD15 and platelets on their own.\n# Subset the similar datasets cd_subset \u0026lt;- c(1, 3, 4, 5) intestine_subset \u0026lt;- c(6, 8, 9) The grey areas are absent genes for the dataset in question. This is too dense (being some 18,517 observations long) and with the dissmilarity of some features make it impossible to see patterns.\nHOX gene clusters We investigate the clustering of HOX genes; these are a family of associated genes. We expect to see them cluster together in each dataset.\nWe see that for the HOX genes present in all datasets we have the majority in a common cluster across datasets, particularly in the blood cell types. There is slightly less homogeneity in the intestinal samples. We check to see if the clustering is more unanimous in the subsets of similar datasets.\nRecalling the clustering of datasets from the initial heatmap, we investigate these groupings. We inspect different combinations trying the CD combinations and the intestinal combinations.\nTo show that platelets and CD15 do not sit natually in any clustering of datasets we include the following heatmaps. The sparseness of the platelets dataset causes confusion and CD15 does not sit naturally in either clustering.\n  References Bardenet, Rémi, Arnaud Doucet, and Chris Holmes. 2017. “On Markov Chain Monte Carlo Methods for Tall Data.” The Journal of Machine Learning Research 18 (1). JMLR. org: 1515–57.\n Betancourt, Michael. 2017. “A Conceptual Introduction to Hamiltonian Monte Carlo.” arXiv Preprint arXiv:1701.02434.\n Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n Kolde, Raivo. 2019. Pheatmap: Pretty Heatmaps. https://CRAN.R-project.org/package=pheatmap.\n Mason, Samuel A, Faiz Sayyid, Paul DW Kirk, Colin Starr, and David L Wild. 2016. “MDI-Gpu: Accelerating Integrative Modelling for Genomic-Scale Data Using Gp-Gpu Computing.” Statistical Applications in Genetics and Molecular Biology 15 (1). De Gruyter: 83–86.\n Neuwirth, Erich. 2014. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n   ","date":1550620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550620800,"objectID":"7f190e072a5ff929ac1d6803061adfb5","permalink":"/post/weeks-1-3/log-weeks-1-3/","publishdate":"2019-02-20T00:00:00Z","relpermalink":"/post/weeks-1-3/log-weeks-1-3/","section":"post","summary":"Prelude Many of the R chunks below require these R packages (Kolde 2019, Dowle and Srinivasan (2019), Neuwirth (2014)):\nlibrary(pheatmap) library(data.table) library(RColorBrewer)  Reading The first step in the project is to understand the tool we are using. Therefore a study of Mason et al. (2016) and reading the manual of the associated program were the first steps. Expecting that this would have difficulties scaling to nine datasets different sampling methods were researched (Bardenet, Doucet, and Holmes 2017).","tags":["Chris Wallace","MDI"],"title":"MDI: Weeks 1 - 3","type":"post"},{"authors":null,"categories":[],"content":" Multiple Dataset Integration If we have observed paired datasets \\(X_1=(x_{1,1},\\ldots, x_{n,1})\\), \\(X_2=(x_{1,2},\\ldots, x_{n,2})\\), where observations in the \\(i\\)th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate. If the two datasets have the same structure but different signal-to-noise ratios this would reduce the signal in the final clustering. In both these cases independent models on each dataset would be preferable. Kirk et al. (2012) suggest a method to carry out clustering on both datasets where common information is used but two individual clusterings are outputted. This method is driven by the allocation prior:\n\\[p(c_{i,1}, c_{i,2} | \\phi ) \\propto \\pi_{i,1} \\pi_{i,2} ( 1 + \\phi \\mathbb{I} ( c_{i,1} = c_{i,2}))\\]\nHere \\(\\phi \\in \\mathbb{R}_{+}\\) controls the strength of association between datasets. The above equation states that the probability of allocating individual \\(i\\) to component \\(c_{i,1}\\) in dataset 1 and to component \\(c_{i,2}\\) in dataset 2 is proportional to the proportion of these components within each dataset and up-weighted by \\(\\phi\\) if the individual has the same labelling in each dataset. Thus as \\(\\phi\\) grows the correlation between the clusterings grow and we are more likely to see the same clustering emerge from each dataset. Conversely if \\(\\phi = 0\\) we have independent mixture models. Note that Kirk et al. (2012) include the generalised case for \\(L\\) datasets for any \\(L \\in \\mathbb{N}\\).\nMDI has been applied to precision medicine, specifically glioblastoma sub-typing (Savage et al. 2013), in the past showing its potential as a tool.\nReferences Kirk, Paul, Jim E Griffin, Richard S Savage, Zoubin Ghahramani, and David L Wild. 2012. “Bayesian Correlated Clustering to Integrate Multiple Datasets.” Bioinformatics 28 (24). Oxford University Press: 3290–7.\n Savage, Richard S, Zoubin Ghahramani, Jim E Griffin, Paul Kirk, and David L Wild. 2013. “Identifying Cancer Subtypes in Glioblastoma by Combining Genomic, Transcriptomic and Epigenomic Data.” arXiv Preprint arXiv:1304.3577.\n    ","date":1550534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550534400,"objectID":"9ed09ed07e86dc171d15ca8369ddf7b3","permalink":"/post/intro-mdi/an-introduction-to-mdi/","publishdate":"2019-02-19T00:00:00Z","relpermalink":"/post/intro-mdi/an-introduction-to-mdi/","section":"post","summary":"Multiple Dataset Integration If we have observed paired datasets \\(X_1=(x_{1,1},\\ldots, x_{n,1})\\), \\(X_2=(x_{1,2},\\ldots, x_{n,2})\\), where observations in the \\(i\\)th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate.","tags":["MDI","Paul Kirk"],"title":"An introduction to MDI","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536447600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536447600,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.\n  Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":null,"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":null,"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]