[{"authors":["admin"],"categories":null,"content":"I am a MSc student currently writing my dissertation as part of the Wallace Group in the Department of Medicine at Cambridge University. The dissertation aims to define tissue specific gene sets by clustering gene expression data across multiple tissue types using Multiple Dataset Integration (MDI), an unsupervised clustering method based upon Dirichlet processes.\nPreviously I have worked with Paul Kirk, Laurent Gatto and Ollie Crook to extend MDI to a semi-supervised predictive tool in spatial proetomics. This is available online in tagm-mdi.\nI have also worked with Gerrit Gort, Elias Kaiser and Rachel Schipper to model the Farquhar-van Cammerer-Berry model of photosynthesis. As all of the data for this task is repeated measurements from individual plants, we hope to use mixed-effects models to account for this correlation in the data.\nMy research interests include Bayesian clustering applied to \u0026lsquo;omics data to extract biological information. Within \u0026lsquo;omics we have huge quantities of data; interpreting this and creating a coherent story of disease is a non-tirivial problem. My aim is to use Bayesian clustering methods (particularly non-parametric methods) in the area of immunology to help contribute to the understanding of disease.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a MSc student currently writing my dissertation as part of the Wallace Group in the Department of Medicine at Cambridge University. The dissertation aims to define tissue specific gene sets by clustering gene expression data across multiple tissue types using Multiple Dataset Integration (MDI), an unsupervised clustering method based upon Dirichlet processes.\nPreviously I have worked with Paul Kirk, Laurent Gatto and Ollie Crook to extend MDI to a semi-supervised predictive tool in spatial proetomics.","tags":null,"title":"Stephen D. Coleman","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536447600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536447600,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":[],"content":" Summary In this period I went to Women in Data Science (WiDS), Zurich, got the HPC scripts running properly (an \u0026amp; lost me a day or two), briefly inspected mixing for the gene sets Chris gave me and got the MATLAB version of MDI running (possibly incorrectly - I have to ask PK).\n WiDS Some nice speakers that were of particular interest to me:\nMaria Rodriguez Martinez of IBM gave a talk on predicting drug effectiveness which was interesting and overlapped with the Dream challenge from last year; Natasha Antropova of Google DeepMind talked about their collaboration with CRUK on working at breast cancer diagnosis via computer vision; Sandhya Prabhakaran talked about Bayesian fuzzy clustering via an Indian Buffet process - an interesting talk but a little light on details (as to be expected at such an open conference perhaps); Ruth Urner talked about asymptotic bounds on ML methods and the ability to guarantee some bound on generalisability. Quite information theoretic, but very interesting.  Beyond this I had some nice conversations with:\nMargaux Penwarden of McKinsey/QuantumBlack about fairness and explainability in A.I.; Nicholas Kelley of Novartis about their plans for integrating machine learning into their business; and Lise Regnier from Warner Bros. She had given a great talk on being a data scientist in an environment unused to it and recommended the use osf SHapley Additive exPlanations (SHAP) a unified approach to explain the output of any machine learning model. I haven’t looked into this yet, but she claimed to use it to make more causal claims.  It was an interesting conference - got quite a bit of exposure to different ideas, problems and methods than I normally think about. Sarah Ebling’s talk on building tools to translate sign language and Michelle Sebag talking about meta-features are good examples of this. Beyond purely intellectual pursuits, I would reccommend this conference if one was coming towards a point where one was considering moving to industry or wanted to see what skills are sought in industry. There was quite a bit of fishing for candidates from different companies.\n HPC I had a bash script calling MDI across 1,000 seeds. As I am only recoring the 500th iteration I was running a number of these side-by-side in the node. I followed a post on Stack Exchange that reccommended using “\u0026amp;” to force things into parallel. However, slurm saw everything go into the background and assumed the script ran and killed it instantly. I had to include a “wait” command after my for loop to ensure that the script was not instantly terminated.\nStuart also helped out with installing R packages on the HPC - I’ve added his instrucitons to the group info doc a section since added to by Kath.\n Mixing in gene subsets The clusters do not become fixed as quickly in the small and medium-sized gene sets. Label flipping does seem to occur a little bit, but the mixtures are still a little sticky - comparing different seeds we see different numbers of clusters emerge in the datasets; we might have to use the Split-Merge step of the MATLAB code for the subsetted data too and we should consider model averaging if we don’t use this. In the big gene set the behaviour is quite similar to the full dataset.\nCD14 Rand index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n   IL Rand index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n   PLA Rand Index Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n  Heatmaps Random seed set to 1\n Random seed set to 4\n Random seed set to 10\n    ","date":1555459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"9ac173c4ada34684bdea36de222293af","permalink":"/post/weeks-8-9/mdi-weeks-8-9/","publishdate":"2019-04-17T00:00:00Z","relpermalink":"/post/weeks-8-9/mdi-weeks-8-9/","section":"post","summary":"Summary In this period I went to Women in Data Science (WiDS), Zurich, got the HPC scripts running properly (an \u0026amp; lost me a day or two), briefly inspected mixing for the gene sets Chris gave me and got the MATLAB version of MDI running (possibly incorrectly - I have to ask PK).\n WiDS Some nice speakers that were of particular interest to me:\nMaria Rodriguez Martinez of IBM gave a talk on predicting drug effectiveness which was interesting and overlapped with the Dream challenge from last year; Natasha Antropova of Google DeepMind talked about their collaboration with CRUK on working at breast cancer diagnosis via computer vision; Sandhya Prabhakaran talked about Bayesian fuzzy clustering via an Indian Buffet process - an interesting talk but a little light on details (as to be expected at such an open conference perhaps); Ruth Urner talked about asymptotic bounds on ML methods and the ability to guarantee some bound on generalisability.","tags":["MDI"],"title":"MDI: Weeks 8 \u0026 9","type":"post"},{"authors":null,"categories":[],"content":" Gene subsetting The aim of this week was to analyse the data at the level of the subsets provided by Chris. Basically we want to run the data through our pipeline in subsets of genes.\nPipeline The pipeline stands at:\nDownload the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data, remove NAs and apply vsn; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; and Apply MDI.  I made a mistake in originally doing step 1 after step 3, but this does not make sense as it is possible that the missingness is outside of this subset (so we do not have to remove any points) or entirely in this subset (in which case imputation may be misleading).\n Subsetting the data The gene subset data was saved in a list of Data frame’s. Not data.frame’s. Apparently Bioconductor has its own version of the data frame. Once we realised this and loaded the correct package this was not a problem.\nUsing the key relating probe IDs to genes and the names of the genes in the subsets we created smaller .csv files containing the expression data relating only to the probes present that map to these genes.\n Transpose, remove NAs and apply VSN The only point of note is that we had harsher cirteria for removing people / probes in the small and medium datasets. If there was 5% of points missing we stripped out the person / probe. This had no impact as none of the people or probes in these subsets are above this threshold of missingness.\nlibrary(data.table) small_obs_lost \u0026lt;- fread(\u0026quot;Observations_lost_small.csv\u0026quot;, header = T) med_obs_lost \u0026lt;- fread(\u0026quot;Observations_lost_med.csv\u0026quot;, header = T) head(small_obs_lost) ## File N_probes_lost N_people_lost ## 1: CD14_GE_Corrected4_Covars_smallnet 0 0 ## 2: CD15_GE_Corrected4_Covars_smallnet 0 0 ## 3: CD19_GE_Corrected4_Covars_smallnet 0 0 ## 4: CD4_GE_Corrected4_Covars_smallnet 0 0 ## 5: CD8_GE_Corrected4_Covars_smallnet 0 0 ## 6: IL_GE_Corrected4_Covars_smallnet 0 0 head(med_obs_lost) ## File N_probes_lost N_people_lost ## 1: CD14_GE_Corrected4_Covars_midnet 0 0 ## 2: CD15_GE_Corrected4_Covars_midnet 0 0 ## 3: CD19_GE_Corrected4_Covars_midnet 0 0 ## 4: CD4_GE_Corrected4_Covars_midnet 0 0 ## 5: CD8_GE_Corrected4_Covars_midnet 0 0 ## 6: IL_GE_Corrected4_Covars_midnet 0 0  PCA Individuals We identify outliers on a visual basis in the biplots. I will show a subset of plots as between the 3 subsets and 9 tissue types we have 27 plots which seems a little heavy. The script, with the full list of outliers dropped, is found here. I found tibbles a nice way of keeping track of gene subset, tissue and data. The final tibble held a column for each of these as well as a “Cleaned data” column. It made it very easy to have all the data in one place and to save it in a nice compressed form.\nPCA plot for individuals in the large subset of genes in the CD15 dataset.\n PCA plot for individuals in the medium subset of genes in the CD15 dataset.\n PCA plot for individuals in the small subset of genes in the CD15 dataset. Note that the outliers are the same individuals as the preceding plots.\n  Probes As we had smaller gene sets, the PCA for the Probes was also created. A sample of biplots is included.\nFor the small subset of genes:\nPCA for probe expression in small gene subset of CD4 dataset.\n PCA for probe expression in small gene subset of PLA dataset.\n For the medium subset of genes:\nPCA for probe expression in medium gene subset of CD8 dataset.\n PCA for probe epxression in medium gene subset of PLA dataset.\n    ","date":1553731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553731200,"objectID":"57de724bdfdc70648893389a05e405cb","permalink":"/post/week-7/mdi-week-7/","publishdate":"2019-03-28T00:00:00Z","relpermalink":"/post/week-7/mdi-week-7/","section":"post","summary":"Gene subsetting The aim of this week was to analyse the data at the level of the subsets provided by Chris. Basically we want to run the data through our pipeline in subsets of genes.\nPipeline The pipeline stands at:\nDownload the data; Subset the data using the gene subsets (divided into big, med, small); Transpose the data, remove NAs and apply vsn; Inspect the data by PCA and remove outlier individuals for each dataset in each gene set; To apply MDI we require that each dataset have the same row names in the same order, so we re-arrange our datasets to have common order of probes and include rows of 0’s for probes entirely missing using this script; and Apply MDI.","tags":["MDI"],"title":"MDI: Week 7","type":"post"},{"authors":null,"categories":[],"content":" New work PCA plotting We implemented PCA across people (PCA across probes is too dense to be readable). We then eyeballed the results in each dataset and removed outlier individuals. This is not a rigourous method and we welcome arguments for a quantitative method to choose outliers.\nFirst we load the relevant libraries (Dowle and Srinivasan 2019, Wickham et al. (2019), Kassambara and Mundt (2017), Bache and Wickham (2014))\n# Load data.table to access fread and fwrite functions library(data.table) # Load magrittr for the pipe %\u0026gt;% library(magrittr) # For select, filter library(dplyr) # For PCA plots library(factoextra, quietly = T)  Read in the data and create some variables to hold results. This data has had NAs filled using the minimum value present for that probe and removing the probe from that dataset if the probe has missing values for more than 0.1 of the people.\n# Read in data data_dir \u0026lt;- \u0026quot;/home/MINTS/sdc56/Desktop/blogdown_github_pages/content/post/weeks-5-6/Data\u0026quot; files_present \u0026lt;- list.files(path = data_dir) file_name \u0026lt;- grep(\u0026quot;Covars.csv\u0026quot;, files_present, value = TRUE) genes_present \u0026lt;- c() pca_lst \u0026lt;- list() pca_plot_lst \u0026lt;- list() data_lst \u0026lt;- list() # Put all the data in a list of data tables for (f in file_name) { data_lst[[f]] \u0026lt;- fread(paste(data_dir, f, sep = \u0026quot;/\u0026quot;), header = T) } # Acquire the relevant file names files_to_write \u0026lt;- strsplit(names(data_lst), \u0026quot;_?_(.*?)_?\u0026quot;) %\u0026gt;% lapply(\u0026quot;[[\u0026quot;, 2) %\u0026gt;% unlist() num_datasets \u0026lt;- length(data_lst) cleaned_data \u0026lt;- vector(\u0026quot;list\u0026quot;, 9) names(cleaned_data) \u0026lt;- files_to_write Apply the PCA.\nfor (i in 1:num_datasets) { # Carry out PCA and record the biplot raw_file_name \u0026lt;- file_name[[i]] edit_file_name \u0026lt;- files_to_write[[i]] pca_lst[[edit_file_name]] \u0026lt;- .res_pca \u0026lt;- prcomp(t(data_lst[[raw_file_name]][, -1])) pca_title \u0026lt;- paste0(edit_file_name, \u0026quot;: PCA for individuals\u0026quot;) pca_plot_lst[[edit_file_name]] \u0026lt;- fviz_pca_ind(.res_pca, col.ind = \u0026quot;contrib\u0026quot;, # gradient.cols = c(\u0026quot;#00AFBB\u0026quot;, \u0026quot;#E7B800\u0026quot;, \u0026quot;#FC4E07\u0026quot;), title = pca_title ) + scale_color_gradient2( low = \u0026quot;black\u0026quot;, mid = \u0026quot;blue\u0026quot;, high = \u0026quot;red\u0026quot;, midpoint = 1.0 ) } We then visually inspect the PCA plots and remove indviduals we deem to be outliers.\nBased on an inspection of this plot, we decide to remove IPC154 and IPC155 from the CD14 dataset for all following steps.\nSimilarly, for CD15 we remove IPC137. We continue in this vein for all of the 9 datasets.\n Variance stabilisation We wish to standardise the expresison values across probes and to do so apply variance stabilisation (Huber, Von Heydebreck, et al. 2002) after first converting the expression values from \\(log_2\\) scale. We do this in this script which can be called from the command line.\n Gene subsets We select three different subsets of genes using this RScript.\n  Pipeline summary Now our current workflow / pipeline can be described as:\nDownload the data from associated website; Transpose this data and remove and / or fill NAs using this script\n Remove NAs absent from 0.1 of the total people in the dataset; Otherwsie fill the missing values with the minimum present expression value for the probe in question.  (Optional) Select gene subsets; Remove outlier individuals using PCA as described above; Apply VSN using the R package (Huber, von Heydebreck, et al. 2002); and Run MDI.\n   References Bache, Stefan Milton, and Hadley Wickham. 2014. Magrittr: A Forward-Pipe Operator for R. https://CRAN.R-project.org/package=magrittr.\n Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n Huber, Wolfgang, Anja von Heydebreck, Holger Sueltmann, Annemarie Poustka, and Martin Vingron. 2002. “Variance Stabilization Applied to Microarray Data Calibration and to the Quantification of Differential Expression.” Bioinformatics 18 Suppl. 1: S96–S104.\n Huber, Wolfgang, Anja Von Heydebreck, Holger Sültmann, Annemarie Poustka, and Martin Vingron. 2002. “Variance Stabilization Applied to Microarray Data Calibration and to the Quantification of Differential Expression.” Bioinformatics 18 (suppl_1). Oxford University Press: S96–S104.\n Kassambara, Alboukadel, and Fabian Mundt. 2017. Factoextra: Extract and Visualize the Results of Multivariate Data Analyses. http://www.sthda.com/english/rpkgs/factoextra.\n Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n   ","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553212800,"objectID":"fce323d344389f211985cf5270011c3f","permalink":"/post/weeks-5-6/mdi-weeks-5-6/","publishdate":"2019-03-22T00:00:00Z","relpermalink":"/post/weeks-5-6/mdi-weeks-5-6/","section":"post","summary":"New work PCA plotting We implemented PCA across people (PCA across probes is too dense to be readable). We then eyeballed the results in each dataset and removed outlier individuals. This is not a rigourous method and we welcome arguments for a quantitative method to choose outliers.\nFirst we load the relevant libraries (Dowle and Srinivasan 2019, Wickham et al. (2019), Kassambara and Mundt (2017), Bache and Wickham (2014))","tags":["MDI"],"title":"MDI: Weeks 5 \u0026 6","type":"post"},{"authors":null,"categories":[],"content":" Sensible Clustering We check if the modal cluster from the MDI iterations is a sensible decision for allocating probes (note: we referred to median clustering previously. This was wrong). To do this we construct heatmaps comparing the clustering across a sample of iterations and also plot the adjusted Rand index for the clustering at every iteration compared to the modal clustering.\n We plot the adjusted Rand index comparing the allocation at a given iteration (corrected for thinning on the x-axis) to the modal clustering from all recorded iterations.\n We construct a heatmap of the clustering across a sample of iterations.\nIndividual clusterings We also cluster the individual datasets using a Dirichlet process (i.e. we apply MDI with a single dataset). We carry out similar sense checks to ensure that the model clustering is representative.\n  We compare the clustering in the individual vs the multiple dataset cases. Note that the specific label does not matter, we are interested in the membership of clusters but do not have any reason to expect that the labels should correspond. We see that many of the clusters have a largely common membership across the two clusterings, but that there are significant differences.\n    ","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"7eaf2c4bb807134b36b44edd8726591c","permalink":"/post/mdi-week-4/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/mdi-week-4/","section":"post","summary":"Sensible Clustering We check if the modal cluster from the MDI iterations is a sensible decision for allocating probes (note: we referred to median clustering previously. This was wrong). To do this we construct heatmaps comparing the clustering across a sample of iterations and also plot the adjusted Rand index for the clustering at every iteration compared to the modal clustering.\n We plot the adjusted Rand index comparing the allocation at a given iteration (corrected for thinning on the x-axis) to the modal clustering from all recorded iterations.","tags":["MDI","Chris Wallace","Paul Kirk"],"title":"MDI: Week 4","type":"post"},{"authors":null,"categories":[],"content":" Prelude Many of the R chunks below require these R packages (Kolde 2019, Dowle and Srinivasan (2019), Neuwirth (2014)):\nlibrary(pheatmap) library(data.table) library(RColorBrewer)  Reading The first step in the project is to understand the tool we are using. Therefore a study of Mason et al. (2016) and reading the manual of the associated program were the first steps. Expecting that this would have difficulties scaling to nine datasets different sampling methods were researched (Bardenet, Doucet, and Holmes 2017). Hamiltonian Monte Carlo appears a likely candidate to improve the rate of convergence, with Betancourt (2017) providing an explanation of the theoretical framework. These topics were of interest as the MDI implementation uses a Gibbs sampler. We expected that we could make gains in the computational tractability of using all 9 datasets in a single call of MDI with a more clever sampling method.\n Data handling MDI uses data that has common row names across all datasets. The data from the CEDAR cohort is in the form of [people \\(\\times\\) probes]. We want to transpose this; to accomplish this task we wrote an Rscript that can be called form the terminal command line with appropriate arguments to transpose .csv files in a given directory. The data.table package by Dowle and Srinivasan (2019) was of great use in making this quick to run - for our 9 datasets of ~300 people and 8-16 thousand probes it aaproximately 30s using a desktop compuer to read in, transpose, handle missingness and write the file. In comparison, using purrr of the tidyverse suite for even one aspect of the missingness handling increased the time taken to roughly 1 minute 50s.\nThe nine datasets present are six circulating immune cell types (CD4+ T lymphocytes, CD8+ T lymphocytes, CD19+ B lymphocytes, CD14+ monocytes, CD15+ granulocytes, platelets) as well as ileal, colonic, and rectal biopsies (IL, TR, RE datasets respectively).\nAnother script was required to remove all the non-ubiquitous probe IDs. Any probe not present in all datasets was removed to allow MDI to perform as MDI cannot handle missing data. This reduced the set of probes to 4,964.\nWe performed MDI on these 9 reduced datasets with 10,000 iterations, a burn-in of 1,000 and a thinning rate of 25. MDI overfits the data, beginning with 50 clusters (as an approximation of a Dirichlet process - note that we can change the number of clusters present); as part of the sampling is reduced to around 10 occupied clusters per dataset (ranging from 8 - 13). We assumed that the median cluster allocation was the predicted cluster forgetting about the label-flipping problem of unsupervised methods.\nWe constructed a dataframe of the median allocation per dataset for each probe. The probes are translated to the associated gene using the key available online. As some of the probes mapped to non-unique genes we use a matrix to hold our data (as this does not require unique row names in R). We read this in and visually inspect the head of the data.\n# Read in the data and convert to a matrix with apporpriate row names compare_df \u0026lt;- data.table::fread(\u0026quot;allocation_data_run_1.csv\u0026quot;) compare_df_mat \u0026lt;- as.matrix(compare_df[, -10]) row.names(compare_df_mat) \u0026lt;- compare_df$V1 # Inspect the data head(compare_df_mat) ## CD14 CD15 IL CD4 CD8 CD19 PLA RE TR ## GGACT 8 8 8 8 8 8 8 8 8 ## A4GNT 5 6 10 6 6 10 5 5 5 ## AAAS 3 8 3 3 3 3 5 3 3 ## AACS 8 10 8 8 8 8 8 8 8 ## AACSP1 8 6 6 6 8 8 5 6 6 ## NCEH1 10 8 10 10 10 10 8 11 10  Visualisation Note: As one inspects the following plots please recall that the labels are arbitrary and proximity of colouring has no significance (i.e. there is no reason to believe that orange in the heatplots has any association with red).\nUsing this data we generated a heatmap of all the genes allocation across all datasets.\nNotice that we have clusters of datasets; CD4, CD8 and CD14, RE and IL and then CD15, CD19 and TR. Platelets are outside of any clusters of datasets; PLA is also the thinnest dataset with only 8 thousand probes present in the full format.\nThere are 13 clusters present here; to enable comparison we went for a wider colour palette. This is the reason for the garishness of this heatplot. A casual inspection suggests lower similarity than one might expect, particularly considering the selection of data. As we only include the genes that are sufficiently expressed in each cell type to register for measurement we would expect these to include the genes that are most similarly expressed across all tissues. We should consider the pssibility that this is an artifact of not considering label-flipping, but we investigate the clusters in finer detail first.\nInvestigate different combinations We consider the data excluding the platelets. Even this change gives an appearance of greater similarity.\nRecalling the first heatmap of the entire dataset, which included clustering of columns (i.e. the datasets), we consider only the separate clustering of datasets: CD4, CD8, CD14, RE and IL.\nThese are more coherent than our first heatmap where we considered all datasets at once - this suggests that trying to process the output of all 9 datasets at once is a non-trivial task and the naive method of heatmapping all of the data is unlikey to be useful. However, by including clustering of the datasets it is a useful initial step in the exploratory data analysis and will be considered as part of our analysis workflow.\nOut of curiousity we check the clustering and heatmap for the excluded datasets.\nUnsurprisingly this is very noisy, with only small bands of genes clustering across multiple tissues.\n  Including all probes Next we attempt to include all probes present across the 9 datasets. The challenge here is to impute the missing probes in such a fashion as to not add noise to the final clustering. To do this we first inspect the spread of the expression values in the datasets. As this is too large to consider in normal summary statistics, we inspect histograms of these - we notice that all of the probe expression values have very similar means and standard deviations - these are densely (i.e. within 1.0 for the mean, within 0.2 for the standard deviation) distributed around 7.0 and 2.10 respectively.\nWe created an Rscript that finds the list of all unique probe IDs present across the 9 datasets and adds the required rows to each .csv file (filled with 0’s but any arbitrarily distant number from the range inhabitated by the actual measurements should be acceptable) and rearranging to have common row names and row orders in each dataset for all 18,517 prob IDs. Using these new datasets we perform MDI with the same arguments.\nThis script also saves a binary matrix indicating for each probe which datasets it is present in. We use this as part of a sense check to ensure that the cluster containing the imputed probes contains no other members. This is done by taking the Hadamard product of the binary matrix with the allocation matrix and comparing the clusters occupied in this to those of the allocation matrix. Ideally one of the clusters should have completed disappeared and been replaced by a 0 cluster. This is the case below.\nAs in the initial attempt we feed in our data and move the to a matrix format.\n# Read in the data and convert to a matrix with apporpriate row names compare_df_all \u0026lt;- data.table::fread(\u0026quot;allocation_data_run_2.csv\u0026quot;) compare_df_all_mat \u0026lt;- as.matrix(compare_df_all[, -10]) row.names(compare_df_all_mat) \u0026lt;- compare_df_all$V1 We now create a heatmap of these genes.\nNotice the clustering of datasets; we have groupings of the intestinal sample cells (IL, RE and TR), of CD14, CD19, CD4 and CD8 and then CD15 and platelets on their own.\n# Subset the similar datasets cd_subset \u0026lt;- c(1, 3, 4, 5) intestine_subset \u0026lt;- c(6, 8, 9) The grey areas are absent genes for the dataset in question. This is too dense (being some 18,517 observations long) and with the dissmilarity of some features make it impossible to see patterns.\nHOX gene clusters We investigate the clustering of HOX genes; these are a family of associated genes. We expect to see them cluster together in each dataset.\nWe see that for the HOX genes present in all datasets we have the majority in a common cluster across datasets, particularly in the blood cell types. There is slightly less homogeneity in the intestinal samples. We check to see if the clustering is more unanimous in the subsets of similar datasets.\nRecalling the clustering of datasets from the initial heatmap, we investigate these groupings. We inspect different combinations trying the CD combinations and the intestinal combinations.\nTo show that platelets and CD15 do not sit natually in any clustering of datasets we include the following heatmaps. The sparseness of the platelets dataset causes confusion and CD15 does not sit naturally in either clustering.\n  References Bardenet, Rémi, Arnaud Doucet, and Chris Holmes. 2017. “On Markov Chain Monte Carlo Methods for Tall Data.” The Journal of Machine Learning Research 18 (1). JMLR. org: 1515–57.\n Betancourt, Michael. 2017. “A Conceptual Introduction to Hamiltonian Monte Carlo.” arXiv Preprint arXiv:1701.02434.\n Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n Kolde, Raivo. 2019. Pheatmap: Pretty Heatmaps. https://CRAN.R-project.org/package=pheatmap.\n Mason, Samuel A, Faiz Sayyid, Paul DW Kirk, Colin Starr, and David L Wild. 2016. “MDI-Gpu: Accelerating Integrative Modelling for Genomic-Scale Data Using Gp-Gpu Computing.” Statistical Applications in Genetics and Molecular Biology 15 (1). De Gruyter: 83–86.\n Neuwirth, Erich. 2014. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n   ","date":1550620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550620800,"objectID":"7f190e072a5ff929ac1d6803061adfb5","permalink":"/post/weeks-1-3/log-weeks-1-3/","publishdate":"2019-02-20T00:00:00Z","relpermalink":"/post/weeks-1-3/log-weeks-1-3/","section":"post","summary":"Prelude Many of the R chunks below require these R packages (Kolde 2019, Dowle and Srinivasan (2019), Neuwirth (2014)):\nlibrary(pheatmap) library(data.table) library(RColorBrewer)  Reading The first step in the project is to understand the tool we are using. Therefore a study of Mason et al. (2016) and reading the manual of the associated program were the first steps. Expecting that this would have difficulties scaling to nine datasets different sampling methods were researched (Bardenet, Doucet, and Holmes 2017).","tags":["Chris Wallace","MDI"],"title":"MDI: Weeks 1 - 3","type":"post"},{"authors":null,"categories":[],"content":" Multiple Dataset Integration If we have observed paired datasets \\(X_1=(x_{1,1},\\ldots, x_{n,1})\\), \\(X_2=(x_{1,2},\\ldots, x_{n,2})\\), where observations in the \\(i\\)th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate. If the two datasets have the same structure but different signal-to-noise ratios this would reduce the signal in the final clustering. In both these cases independent models on each dataset would be preferable. Kirk et al. (2012) suggest a method to carry out clustering on both datasets where common information is used but two individual clusterings are outputted. This method is driven by the allocation prior:\n\\[p(c_{i,1}, c_{i,2} | \\phi ) \\propto \\pi_{i,1} \\pi_{i,2} ( 1 + \\phi \\mathbb{I} ( c_{i,1} = c_{i,2}))\\]\nHere \\(\\phi \\in \\mathbb{R}_{+}\\) controls the strength of association between datasets. The above equation states that the probability of allocating individual \\(i\\) to component \\(c_{i,1}\\) in dataset 1 and to component \\(c_{i,2}\\) in dataset 2 is proportional to the proportion of these components within each dataset and up-weighted by \\(\\phi\\) if the individual has the same labelling in each dataset. Thus as \\(\\phi\\) grows the correlation between the clusterings grow and we are more likely to see the same clustering emerge from each dataset. Conversely if \\(\\phi = 0\\) we have independent mixture models. Note that Kirk et al. (2012) include the generalised case for \\(L\\) datasets for any \\(L \\in \\mathbb{N}\\).\nMDI has been applied to precision medicine, specifically glioblastoma sub-typing (Savage et al. 2013), in the past showing its potential as a tool.\nReferences Kirk, Paul, Jim E Griffin, Richard S Savage, Zoubin Ghahramani, and David L Wild. 2012. “Bayesian Correlated Clustering to Integrate Multiple Datasets.” Bioinformatics 28 (24). Oxford University Press: 3290–7.\n Savage, Richard S, Zoubin Ghahramani, Jim E Griffin, Paul Kirk, and David L Wild. 2013. “Identifying Cancer Subtypes in Glioblastoma by Combining Genomic, Transcriptomic and Epigenomic Data.” arXiv Preprint arXiv:1304.3577.\n    ","date":1550534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550534400,"objectID":"9ed09ed07e86dc171d15ca8369ddf7b3","permalink":"/post/intro-mdi/an-introduction-to-mdi/","publishdate":"2019-02-19T00:00:00Z","relpermalink":"/post/intro-mdi/an-introduction-to-mdi/","section":"post","summary":"Multiple Dataset Integration If we have observed paired datasets \\(X_1=(x_{1,1},\\ldots, x_{n,1})\\), \\(X_2=(x_{1,2},\\ldots, x_{n,2})\\), where observations in the \\(i\\)th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate.","tags":["MDI","Paul Kirk"],"title":"An introduction to MDI","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536447600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536447600,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00+01:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.\n  Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":null,"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":null,"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]