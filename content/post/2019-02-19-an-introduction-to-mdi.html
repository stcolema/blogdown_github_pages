---
title: 'An introduction to MDI'
author: Stephen Coleman
date: '2019-02-19'
slug: an-introduction-to-mdi
categories: []
tags:
  - MDI
  - Paul Kirk
bibliography: mdi.bib
---



<div id="multiple-dataset-integration" class="section level1">
<h1>Multiple Dataset Integration</h1>
<p>If we have observed paired datasets <span class="math inline">\(X_1=(x_{1,1},\ldots, x_{n,1})\)</span>, <span class="math inline">\(X_2=(x_{1,2},\ldots, x_{n,2})\)</span>, where observations in the <span class="math inline">\(i\)</span>th row of each dataset represent information about the same individual. We would like to cluster using information common to both datasets. One could concatenate the datasets, adding additional covariates for each individual. However, if the two datasets have different clustering structures this would reduce the signal of both clusterings and probably have one dominate. If the two datasets have the same structure but different signal-to-noise ratios this would reduce the signal in the final clustering. In both these cases independent models on each dataset would be preferable. <span class="citation">Kirk et al. (2012)</span> suggest a method to carry out clustering on both datasets where common information is used but two individual clusterings are outputted. This method is driven by the allocation prior:</p>
<p><span class="math display">\[p(c_{i,1}, c_{i,2} | \phi ) \propto \pi_{i,1} \pi_{i,2} ( 1 + \phi \mathbb{I} ( c_{i,1} = c_{i,2}))\]</span></p>
<p>Here <span class="math inline">\(\phi \in \mathbb{R}_{+}\)</span> controls the strength of association between datasets. The above equation states that the probability of allocating individual <span class="math inline">\(i\)</span> to component <span class="math inline">\(c_{i,1}\)</span> in dataset 1 and to component <span class="math inline">\(c_{i,2}\)</span> in dataset 2 is proportional to the proportion of these components within each dataset and up-weighted by <span class="math inline">\(\phi\)</span> if the individual has the same labelling in each dataset. Thus as <span class="math inline">\(\phi\)</span> grows the correlation between the clusterings grow and we are more likely to see the same clustering emerge from each dataset. Conversely if <span class="math inline">\(\phi = 0\)</span> we have independent mixture models. Note that <span class="citation">Kirk et al. (2012)</span> include the generalised case for <span class="math inline">\(L\)</span> datasets for any <span class="math inline">\(L \in \mathbb{N}\)</span>.</p>
<p>MDI has been applied to precision medicine, specifically glioblastoma sub-typing <span class="citation">(Savage et al. 2013)</span>, in the past showing its potential as a tool.</p>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-kirk2012bayesian">
<p>Kirk, Paul, Jim E Griffin, Richard S Savage, Zoubin Ghahramani, and David L Wild. 2012. “Bayesian Correlated Clustering to Integrate Multiple Datasets.” <em>Bioinformatics</em> 28 (24). Oxford University Press: 3290–7.</p>
</div>
<div id="ref-savage2013identifying">
<p>Savage, Richard S, Zoubin Ghahramani, Jim E Griffin, Paul Kirk, and David L Wild. 2013. “Identifying Cancer Subtypes in Glioblastoma by Combining Genomic, Transcriptomic and Epigenomic Data.” <em>arXiv Preprint arXiv:1304.3577</em>.</p>
</div>
</div>
</div>
</div>
